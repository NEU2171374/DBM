论文二主要实现创新点：
1-A:基于上一部分，基于元路径的随机游走。区别于上一点，计算包含电影和人员节点。分别计算出特征向量；
下一步根据人员的推荐，推荐最近似的10个人，是个人里面的关联电影组成电影推荐集合，被推荐的电影，
与目标人员关联电影做余弦差，众多差中，选Min作为最终值，最终值排列，由小到大进行推荐。



=========================================================================================================
数据清洗规则：只选择评分大于等于4分，表示有过观影记录，小于4分，认为没看过，保留交互记录大于5次的数据，剩余数据2-8拆分

MovieLens数据集
删除人员十个人：10 [5155, 3642, 1091, 4365, 3488, 4192, 4295, 4636, 4349, 5850]
删除的记录个数为: 39条
最后表大小 (575242, 3) 总共57万条数据
用户数量： 6028
电影数量： 3533
数据稀疏度：2.7% 【说明:感觉有点低啊】


=========================================================================================================

主算法：敏感性参数：嵌入维度、游走长度、窗口大小【相似邻居长度、相似邻居窗口大小】、alpha[人员系数]、beta[电影系数]
实验目标：F1指标超过11%就是胜利
正式实验，嵌入维度定在128维度

先做游走长度和窗口大小最佳参数，起始默认为10和5。
相似邻居长度，定在40，窗口大小定在10

alpha和beta先定在0.5，在找最佳参数

=========================================================================================================
MovieTweetings
数据清洗规则：只选择评分大于等于5分，表示有过观影记录，小于5分，认为没看过，剩余数据2-8拆分，交互记录大于50次的用户进行2-8拆分

# 最小电影编号100008 ,只要小于100000就是人

删除评分次数在50次以下的记录: 354589
data.shape (472096, 3)
train_set.shape (377676, 3)
test_set.shape (94420, 3)

人员数量 3574
电影数量 28447
数据稀疏度：0.46%

实现数据集：全部评分.csv
训练集：推特train.csv
测试集：推特test.csv


=========================================================================================================



















































